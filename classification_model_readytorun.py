# -*- coding: utf-8 -*-
"""Copy of Classification Model - Revenues Classes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1psWDFovFX5rTJHVpAd0BloOyVrHgle1U
"""

# ‚úÖ FINAL CLASSIFICATION MODEL - REVENUES (High / Medium / Low)
# XGBoostClassifier with AutoML hyperparameters

from google.colab import files
import io
import pandas as pd
import numpy as np

# 1Ô∏è‚É£ Upload Dataset
print("Upload your CSV (Classification Revenues dataset per model.csv)...")
uploaded = files.upload()
file_name = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[file_name]))
print("‚úÖ Loaded:", df.shape)
display(df.head())

# 2Ô∏è‚É£ Prepare Data
target = "Revenues Class"
if target not in df.columns:
    raise ValueError(f"Column '{target}' not found in dataset.")

df = df.dropna(subset=[target])
X = df.drop(columns=[target])
y = df[target]

# 3Ô∏è‚É£ Preprocessing
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Detect column types
num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()
cat_cols = X.select_dtypes(include=['object']).columns.tolist()

# Detect and extract date parts
date_cols = []
for c in cat_cols:
    try:
        pd.to_datetime(X[c])
        date_cols.append(c)
    except:
        pass

for c in date_cols:
    s = pd.to_datetime(X[c], errors='coerce')
    X[c + '_year'] = s.dt.year
    X[c + '_month'] = s.dt.month
    X[c + '_day'] = s.dt.day
    X[c + '_weekday'] = s.dt.weekday
X = X.drop(columns=date_cols)
cat_cols = [c for c in X.select_dtypes(include=['object']).columns]

# Encode target labels
le = LabelEncoder()
y_enc = le.fit_transform(y)

# Column Transformer
num_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="mean"))
])
cat_pipe = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
])

preprocess = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
])

# 4Ô∏è‚É£ Model setup (AutoML Hyperparameters)
xgb = XGBClassifier(
    booster="gbtree",
    colsample_bytree=1,
    eta=0.4,
    gamma=0,
    grow_policy="lossguide",
    max_bin=255,
    max_depth=10,
    max_leaves=0,
    n_estimators=50,
    objective="reg:logistic",
    reg_alpha=2.3958333333333335,
    reg_lambda=0.20833333333333334,
    subsample=0.6,
    tree_method="hist",
    random_state=42
)

model = Pipeline([
    ("pre", preprocess),
    ("clf", xgb)
])

# 5Ô∏è‚É£ Split and Train
X_train, X_test, y_train, y_test = train_test_split(X, y_enc, stratify=y_enc, test_size=0.25, random_state=42)
print("Training XGBoost model...")
model.fit(X_train, y_train)
print("‚úÖ Training complete.")

# 6Ô∏è‚É£ Evaluation Metrics
y_pred = model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average='weighted')
rec = recall_score(y_test, y_pred, average='weighted')
f1w = f1_score(y_test, y_pred, average='weighted')

# Display metrics table
metrics_table = pd.DataFrame({
    "Metric": ["Accuracy", "Precision (Weighted)", "Recall (Weighted)", "F1-Score (Weighted)"],
    "Value": [acc, prec, rec, f1w]
})
print("\nüìä Model Performance:")
display(metrics_table)

print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred, target_names=le.classes_))

# 7Ô∏è‚É£ Feature Importances
xgb_model = model.named_steps["clf"]
try:
    feature_names = model.named_steps["pre"].get_feature_names_out()
except Exception:
    feature_names = [f"f{i}" for i in range(len(xgb_model.feature_importances_))]

feat_imp = pd.DataFrame({
    "Feature": feature_names,
    "Importance": xgb_model.feature_importances_
}).sort_values("Importance", ascending=False).reset_index(drop=True)

print("\nTop 20 Most Important Features:")
display(feat_imp.head(20))