# -*- coding: utf-8 -*-
"""TS Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tip73b2_E3uKn0XlxiqSZnHvoAxhcFAP
"""

# Traffic Forecasting Model - Google Colab Version
# Adapted from Azure AutoML Generated Code

# ============================================================================
# PART 1: INSTALLATION AND IMPORTS
# ============================================================================

# Install required packages
!pip install scikit-learn pandas numpy matplotlib seaborn openpyxl -q

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import ElasticNet
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error
from datetime import timedelta
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (15, 6)

# ============================================================================
# PART 2: DATA LOADING
# ============================================================================

# Upload your CSV file when prompted
from google.colab import files
print("Please upload your traffic dataset CSV file:")
uploaded = files.upload()

# Load the data
filename = list(uploaded.keys())[0]
df = pd.read_csv(filename)

# Convert Date column to datetime
df['Date'] = pd.read_csv(filename, parse_dates=['Date'])['Date']
df = df.sort_values('Date').reset_index(drop=True)

print(f"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
print(f"Date range: {df['Date'].min()} to {df['Date'].max()}")
print(f"\nFirst few rows:")
print(df.head())

# ============================================================================
# PART 3: FEATURE ENGINEERING
# ============================================================================

def create_time_features(df):
    """Create time-based features from the Date column"""
    df = df.copy()

    # Basic time features
    df['_automl_year'] = df['Date'].dt.year
    df['_automl_month'] = df['Date'].dt.month
    df['_automl_day'] = df['Date'].dt.day
    df['_automl_wday'] = df['Date'].dt.dayofweek
    df['_automl_quarter'] = df['Date'].dt.quarter
    df['_automl_week'] = df['Date'].dt.isocalendar().week
    df['_automl_qday'] = df['Date'].dt.day
    df['_automl_half'] = (df['Date'].dt.month > 6).astype(int)

    return df

def create_lag_features(df, target_col, lags=[1]):
    """Create lag features"""
    df = df.copy()
    for lag in lags:
        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
    return df

def create_rolling_features(df, target_col, window=2):
    """Create rolling window features"""
    df = df.copy()
    df[f'{target_col}_rolling_min_{window}'] = df[target_col].shift(1).rolling(window=window).min()
    df[f'{target_col}_rolling_max_{window}'] = df[target_col].shift(1).rolling(window=window).max()
    df[f'{target_col}_rolling_mean_{window}'] = df[target_col].shift(1).rolling(window=window).mean()
    return df

# ============================================================================
# PART 4: DATA PREPARATION
# ============================================================================

# Create features
df_processed = create_time_features(df)
df_processed = create_lag_features(df_processed, 'Total_Traffic', lags=[1])
df_processed = create_rolling_features(df_processed, 'Total_Traffic', window=2)

# Fill missing values (from lag/rolling features)
numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
df_processed[numeric_cols] = df_processed[numeric_cols].fillna(method='ffill').fillna(method='bfill')

# Encode categorical variables
categorical_cols = ['Day_Name', 'Season', 'Holiday_Name']
df_encoded = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=False)

print(f"\nProcessed dataset: {df_encoded.shape[1]} features")

# ============================================================================
# PART 5: TRAIN-TEST SPLIT
# ============================================================================

# Use 80% for training, 20% for testing (time-series split)
train_size = int(len(df_encoded) * 0.8)
train_df = df_encoded.iloc[:train_size].copy()
test_df = df_encoded.iloc[train_size:].copy()

print(f"\nTraining set: {len(train_df)} samples ({train_df['Date'].min()} to {train_df['Date'].max()})")
print(f"Test set: {len(test_df)} samples ({test_df['Date'].min()} to {test_df['Date'].max()})")

# Separate features and target
target_col = 'Total_Traffic'
exclude_cols = ['Date', target_col]
feature_cols = [col for col in df_encoded.columns if col not in exclude_cols]

X_train = train_df[feature_cols]
y_train = train_df[target_col]
X_test = test_df[feature_cols]
y_test = test_df[target_col]
dates_test = test_df['Date']

# ============================================================================
# PART 6: MODEL TRAINING
# ============================================================================

print("\n" + "="*50)
print("TRAINING MODEL")
print("="*50)

# Preprocessing: Robust Scaler
scaler = RobustScaler(quantile_range=(10, 90), with_centering=True, with_scaling=False)
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Model: ElasticNet (as per Azure AutoML)
model = ElasticNet(
    alpha=0.001,
    l1_ratio=0.21842105263157896,
    max_iter=1000,
    tol=0.0001,
    random_state=42
)

# Train the model
model.fit(X_train_scaled, y_train)
print("✓ Model training completed!")

# ============================================================================
# PART 7: MODEL EVALUATION
# ============================================================================

print("\n" + "="*50)
print("MODEL EVALUATION ON TEST SET")
print("="*50)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Calculate metrics
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred) * 100

print(f"\nPerformance Metrics:")
print(f"  R² Score:  {r2:.4f}")
print(f"  MAE:       {mae:.2f}")
print(f"  RMSE:      {rmse:.2f}")
print(f"  MAPE:      {mape:.2f}%")

# ============================================================================
# PART 8: VISUALIZATION - ACTUAL VS PREDICTED
# ============================================================================

print("\n" + "="*50)
print("GENERATING VISUALIZATIONS")
print("="*50)

# Plot 1: Actual vs Predicted Time Series
fig, axes = plt.subplots(2, 1, figsize=(16, 10))

# Full comparison
axes[0].plot(dates_test.values, y_test.values, label='Actual', linewidth=2, color='blue', alpha=0.7)
axes[0].plot(dates_test.values, y_pred, label='Predicted', linewidth=2, color='red', alpha=0.7)
axes[0].set_title('Traffic Forecasting: Actual vs Predicted (Full Test Set)', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Date', fontsize=12)
axes[0].set_ylabel('Total Traffic', fontsize=12)
axes[0].legend(fontsize=11)
axes[0].grid(True, alpha=0.3)

# Zoomed view (first 60 days)
zoom_days = min(60, len(dates_test))
axes[1].plot(dates_test.values[:zoom_days], y_test.values[:zoom_days],
             label='Actual', linewidth=2, marker='o', markersize=4, color='blue', alpha=0.7)
axes[1].plot(dates_test.values[:zoom_days], y_pred[:zoom_days],
             label='Predicted', linewidth=2, marker='s', markersize=4, color='red', alpha=0.7)
axes[1].set_title(f'Zoomed View: First {zoom_days} Days', fontsize=14, fontweight='bold')
axes[1].set_xlabel('Date', fontsize=12)
axes[1].set_ylabel('Total Traffic', fontsize=12)
axes[1].legend(fontsize=11)
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('actual_vs_predicted.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 2: Scatter Plot
fig, ax = plt.subplots(figsize=(10, 8))
ax.scatter(y_test, y_pred, alpha=0.5, s=50)
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
        'r--', lw=2, label='Perfect Prediction')
ax.set_xlabel('Actual Total Traffic', fontsize=12)
ax.set_ylabel('Predicted Total Traffic', fontsize=12)
ax.set_title('Actual vs Predicted Scatter Plot', fontsize=14, fontweight='bold')
ax.legend(fontsize=11)
ax.grid(True, alpha=0.3)

# Add metrics text
textstr = f'R² = {r2:.4f}\nMAE = {mae:.2f}\nRMSE = {rmse:.2f}\nMAPE = {mape:.2f}%'
props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=11,
        verticalalignment='top', bbox=props)

plt.tight_layout()
plt.savefig('scatter_plot.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 3: Residuals Analysis
residuals = y_test.values - y_pred
fig, axes = plt.subplots(1, 2, figsize=(16, 5))

# Residuals over time
axes[0].scatter(dates_test.values, residuals, alpha=0.5, s=30)
axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)
axes[0].set_xlabel('Date', fontsize=12)
axes[0].set_ylabel('Residuals', fontsize=12)
axes[0].set_title('Residuals Over Time', fontsize=14, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Residuals distribution
axes[1].hist(residuals, bins=50, edgecolor='black', alpha=0.7)
axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2)
axes[1].set_xlabel('Residuals', fontsize=12)
axes[1].set_ylabel('Frequency', fontsize=12)
axes[1].set_title('Distribution of Residuals', fontsize=14, fontweight='bold')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('residuals_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ============================================================================
# PART 9: FUTURE FORECASTING (3 YEARS AHEAD)
# ============================================================================

print("\n" + "="*50)
print("FORECASTING 3 YEARS AHEAD")
print("="*50)

# Get the last date in the dataset
last_date = df_encoded['Date'].max()
forecast_days = 365 * 3  # 3 years

# Create future dates
future_dates = pd.date_range(start=last_date + timedelta(days=1),
                              periods=forecast_days, freq='D')

# Create a dataframe for future predictions
future_df = pd.DataFrame({'Date': future_dates})

# We need to create features similar to training data
# For simplicity, we'll use averages for weather and violations
# In production, you'd want actual forecasted weather data

# Get feature columns that need to be filled
numeric_features = ['Year', 'Month', 'Is_Holiday', 'Total_Violations',
                   'Avg_WindSpeed', 'Avg_Precipitation', 'Avg_Snowfall',
                   'Avg_SnowDepth', 'Avg_Temperature_Max', 'Avg_Temperature_Min']

# Fill with historical averages
for col in numeric_features:
    if col in df.columns:
        future_df[col] = df[col].mean()

# Create time features
future_df = create_time_features(future_df)

# For iterative forecasting with lag features
print("Performing iterative forecasting...")
predictions_list = []
last_known_values = df_encoded[target_col].tail(2).values.tolist()

for i in range(len(future_df)):
    row = future_df.iloc[i:i+1].copy()

    # Add lag features
    row[f'{target_col}_lag_1'] = last_known_values[-1]

    # Add rolling features
    if len(last_known_values) >= 2:
        row[f'{target_col}_rolling_min_2'] = min(last_known_values[-2:])
        row[f'{target_col}_rolling_max_2'] = max(last_known_values[-2:])
        row[f'{target_col}_rolling_mean_2'] = np.mean(last_known_values[-2:])
    else:
        row[f'{target_col}_rolling_min_2'] = last_known_values[-1]
        row[f'{target_col}_rolling_max_2'] = last_known_values[-1]
        row[f'{target_col}_rolling_mean_2'] = last_known_values[-1]

    # Encode categorical variables (create dummy columns)
    for col in categorical_cols:
        if col == 'Day_Name':
            day_name = row['Date'].dt.day_name().values[0]
            for day in ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']:
                row[f'{col}_{day}'] = 1 if day == day_name else 0
        elif col == 'Season':
            month = row['Date'].dt.month.values[0]
            if month in [12, 1, 2]:
                season = 'Winter'
            elif month in [3, 4, 5]:
                season = 'Spring'
            elif month in [6, 7, 8]:
                season = 'Summer'
            else:
                season = 'Autumn'
            for s in ['Spring', 'Summer', 'Autumn', 'Winter']:
                row[f'{col}_{s}'] = 1 if s == season else 0
        elif col == 'Holiday_Name':
            # Default to NA for simplicity
            for holiday in df['Holiday_Name'].unique():
                row[f'{col}_{holiday}'] = 0

    # Ensure all feature columns exist
    for col in feature_cols:
        if col not in row.columns:
            row[col] = 0

    # Align columns with training data
    row_features = row[feature_cols].fillna(0)

    # Scale and predict
    row_scaled = scaler.transform(row_features)
    pred = model.predict(row_scaled)[0]

    # Store prediction
    predictions_list.append(pred)
    last_known_values.append(pred)

    if (i + 1) % 365 == 0:
        print(f"  Completed {(i + 1) // 365} year(s)...")

print("✓ Forecasting completed!")

# ============================================================================
# PART 10: VISUALIZE FUTURE FORECASTS
# ============================================================================

# Create forecast dataframe
forecast_df = pd.DataFrame({
    'Date': future_dates,
    'Forecasted_Traffic': predictions_list
})

# Plot historical + forecast
fig, ax = plt.subplots(figsize=(18, 8))

# Plot historical data
ax.plot(df['Date'], df[target_col], label='Historical Data',
        linewidth=2, color='blue', alpha=0.7)

# Plot forecast
ax.plot(forecast_df['Date'], forecast_df['Forecasted_Traffic'],
        label='3-Year Forecast', linewidth=2, color='red', alpha=0.7)

# Add vertical line at forecast start
ax.axvline(x=last_date, color='green', linestyle='--', linewidth=2,
           label='Forecast Start', alpha=0.7)

ax.set_xlabel('Date', fontsize=13)
ax.set_ylabel('Total Traffic', fontsize=13)
ax.set_title('Traffic Forecast: Historical Data + 3-Year Prediction',
             fontsize=15, fontweight='bold')
ax.legend(fontsize=12)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('3year_forecast.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot forecast only (zoomed)
fig, ax = plt.subplots(figsize=(18, 8))
ax.plot(forecast_df['Date'], forecast_df['Forecasted_Traffic'],
        linewidth=2, color='red', marker='o', markersize=2)
ax.set_xlabel('Date', fontsize=13)
ax.set_ylabel('Forecasted Total Traffic', fontsize=13)
ax.set_title('3-Year Traffic Forecast (Detail View)',
             fontsize=15, fontweight='bold')
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('3year_forecast_detail.png', dpi=300, bbox_inches='tight')
plt.show()

# ============================================================================
# PART 11: SAVE RESULTS
# ============================================================================

print("\n" + "="*50)
print("SAVING RESULTS")
print("="*50)

# Save forecast to CSV
forecast_df.to_csv('traffic_forecast_3years.csv', index=False)
print("✓ Forecast saved to: traffic_forecast_3years.csv")

# Save test set predictions
test_results_df = pd.DataFrame({
    'Date': dates_test.values,
    'Actual_Traffic': y_test.values,
    'Predicted_Traffic': y_pred,
    'Residuals': residuals
})
test_results_df.to_csv('test_set_predictions.csv', index=False)
print("✓ Test predictions saved to: test_set_predictions.csv")

# Download files
from google.colab import files
print("\nDownloading files...")
files.download('traffic_forecast_3years.csv')
files.download('test_set_predictions.csv')
files.download('actual_vs_predicted.png')
files.download('scatter_plot.png')
files.download('residuals_analysis.png')
files.download('3year_forecast.png')
files.download('3year_forecast_detail.png')

print("\n" + "="*50)
print("ANALYSIS COMPLETE!")
print("="*50)
print(f"\nSummary:")
print(f"  - Model Performance (R²): {r2:.4f}")
print(f"  - Forecast Period: {forecast_days} days (3 years)")
print(f"  - All files saved and downloaded successfully")
print("\n" + "="*50)